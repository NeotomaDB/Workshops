---
title: "Archiving and Analyzing Vertebrate Paleoecological Data: Best Practices and Current Resources"
author: "Jessica Blois, Edward Davis, Simon Goring, Jack Williams, Eric C. Grimm"
date: "25 October 2016 | SVP 2016 | Salt Lake City, UT"
output: 
  ioslides_presentation:
    css: styles/styles.css
    logo: images/Packrat.png
    widescreen: yes
---

## Learning Objectives

Workshop participants will learn:

- how to **search and acquire** faunal data using web tools and how to peruse the data using online mapping functions. 
- how to use **APIs** (Application Programming Interface) for Neotoma and other databases
- how to use the **neotoma R package** to write scripts to retrieve Neotoma data directly into R for further analysis 


## Agenda
* 9:30 - 10:00am: Getting started
    + Introductions  
    + Getting set up for the day
* 10:00 - 10:30am: Background and intro to Neotoma
* 10:30 - 10:45am: Coffee
* 10:45 - 11:45am: Web explorer intro and sandbox time
* 11:45 - 12:45pm: LUNCH
* 12:45 - 1:45pm: Intro to API and JSON queries
* 1:45 - 2:45pm:  R Neotoma intro 
* 2:45 - 3:00pm: Break
* 3:00 - 4:30pm: Hackathon time

## Getting started
### Resources
- Following along today
    - Intro/Background slides can be viewed through this link:
    http://bit.ly/2fb1HLa
    
    - The primary workshop document can be viewed through this link:
    http://bit.ly/2dEK1a9

- All slides and materials are on GitHub
    - The Neotoma Paleoecology Database
    https://github.com/NeotomaDB
    - The Workshops section
    https://github.com/NeotomaDB/Workshops/tree/master/SVP2016

## Getting started
### Installations
  1. Download and install R (available at https://cran.r-project.org/)
  2. Download and install RStudio Desktop (https://www.rstudio.com/products/rstudio/download3/)
  3. Install the following R packages: **RJSONIO**, **RCurl**, **neotoma**
    + Open up R Studio, then type: install.packages(‘RJSONIO’, ‘RCurl’)
    + **NOTE**: Last minute changes have been made to the `neotoma` package to make the workshop better for everyone.  Please install as:
    
```R
install.packages('devtools')
devtools::install_github("ropensci/neotoma")
```
 
## What is Neotoma?
- Neotoma is a database *consortium*: [www.neotomadb.org](www.neotomadb.org)
- Organized around proxy types
    - historically, brought together several major databases or datasets (i.e. FAUNMAP, COHMAP)
    - moving towards direct entry of individual data files
- The different databases use a common, extendable platform to ensure compatibility across proxy types
- Each proxy community can develop own standards, e.g. for taxonomy

## The Neotoma ecosystem
- Faunal data
    - FAUNMAP, FAUNMAP2 (in progress)
    - MIOMAP (with Tony Barnosky)
    - ANTIGUA (South America megafaunal dates, in progress, with Tony Barnoksy and Emily Lindsey)
    - MQMD (Mexico, in progress, with Joaquin Arroyo Cabrales)
- Pollen and plant macros
- Packrat midden database
- Ostracodes, Diatoms
- Isotopes (coming online soon)
- Use `neotoma::get_table("datasettype")` to see all 25 available types

## Scope and strengths of Neotoma
- Pliocene to present, global
- Chronology tools and storage
- Multiproxy
- Active development community
- Curated database --> high quality data

## Curated database
- Each proxy group has a set of data stewards, led by one or a few lead stewards
- Anyone can deposit data into Neotoma
- Before going 'live', data need to be validated by a data steward
    - Current vertebrate stewards:
        - Edward Davis, Jessica Blois
        - Russ Graham
        - Mike Etnier (Alaska mammals)

## Dataflow
### Getting data into Neotoma
- Data are first entered into a program called *Tilia*, then validated by a steward and pushed up to the database
- Two ways to get data into *Tilia* format
    1. Download Tilia (free), enter data + metadata directly, then send the file to a steward for validation and upload
    2. Contact a data steward and send data the old-fashioned way (via excel files, etc).
        - We will coordinate getting your data into the correct format and uploaded
    - *Note*: option 2 is a slow route, given the other constraints on our time! We are developing an Excel template and tools in R to facilitate data entry  

## Dataflow
### Getting data out of Neotoma
- Focus of this workshop!
    - Neotoma Explorer
    - API
    - R
    - Database snapshots (housed at [www.neotomadb.org/snapshots](www.neotomadb.org/snapshots))

## Key caveats- for Neotoma and all other databases!
- There may be errors or omissions in the data
- There may have been updates to the data that are not stored in the database
    - new dates, changes in taxonomy, etc.
- "Garbage in, garbage out" 
    - The strength of many of the original databases like FAUNMAP and COHMAP was that they convened a group of experts to assess various aspects of data quality. We need to keep applying that same lens to new datasets
    - Data without associated metadata can only go so far
        - *Note*: What is considered "good metadata" changes through time! 
    - When in doubt, record and store as much information as possible.

## Major activities
- Adding new data (MIOMAP, ANTIGUA, MQMD)
- Integration with other databases: grant to facilitate PBDB/Neotoma cross-database searches
- DOIs: assign datasets individual DOIs, which will satisfy NSFs data access guidelines
- Embargos: tools for embargoing data.
    - e.g., enter and validate your data, get a DOI for paper submission, data go 'live' when the paper is published
- Governance and Sustainability
    - Forming a leadership structure
    - Formalizing bylaws and policy
- Education and outreach
    - Partnerships with [SERC](http://serc.carleton.edu/index.html), [Flyover Country](http://fc.umn.edu/), etc.

## Questions and Discussion
- Thoughts, questions??
- Primary vertebrate contacts:
    - Jessica Blois, [jblois@ucmerced.edu](mailto:jblois@ucmerced.edu)
    - Edward Davis, [edavis@uoregon.edu](mailto:edavis@uoregon.edu)
    - Russ Graham, [rgraham@ems.psu.edu](mailto:rgraham@ems.psu.edu)
